{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamjha-46/OTA_MAC/blob/main/WZ_OTA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WddWQqbSZ_qZ"
      },
      "source": [
        "**Importing** **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ftBe-WhDaFaE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sympy as sp\n",
        "import torch\n",
        "torch.set_default_dtype(torch.float64)\n",
        "torch.set_printoptions(precision=15)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JroqmW1MZ5t6"
      },
      "source": [
        "**Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ezmm8jy_Ws5V"
      },
      "outputs": [],
      "source": [
        "### Fast hadamard transform. Recreated from sympy for GPU support\n",
        "def fwht(seq, inverse):\n",
        "    n = len(seq)\n",
        "    if n < 2:\n",
        "        return a\n",
        "    if n&(n-1):\n",
        "        n = 2**n.bit_length()\n",
        "    a = torch.concat((seq, torch.zeros(n-len(seq)).to(device))) # append zeros to make it power of 2\n",
        "    h = 2\n",
        "    while h<=n:\n",
        "        hf = h // 2\n",
        "        i = torch.arange(0,n,h).to(device)\n",
        "        i = i.reshape(len(i), 1)\n",
        "        j = torch.arange(0, hf, 1).to(device)\n",
        "        j = j.repeat(len(i),1)\n",
        "        u, v = a[i+j], a[i+j+hf]\n",
        "        a[i+j], a[i+j+hf] = u+v, u-v\n",
        "        h*=2\n",
        "\n",
        "    if inverse:\n",
        "        a /= n\n",
        "    return a\n",
        "\n",
        "### Uniform quantization\n",
        "def UQ(flat_grad, B, v, Q_space):\n",
        "  norm_flat_grad = flat_grad/K\n",
        "  rand_vect = torch.rand(d).to(device)\n",
        "  f = torch.bucketize(norm_flat_grad, Q_space)\n",
        "  q = torch.where(2*B/K/(v-1)*rand_vect<=torch.subtract(norm_flat_grad, Q_space[f-1]), f, f-1)\n",
        "  return(q)\n",
        "\n",
        "### Lattice encoding\n",
        "def LatE(stat, p, num_blocks, w, d_ext):\n",
        "\tstat = torch.concatenate((stat, torch.zeros(int(d_ext-d)).to(device)))\n",
        "\tstat_ext = stat.reshape(int(num_blocks), p)\n",
        "\tcoeff = w**torch.arange(p).to(device)\n",
        "\tlamda  = torch.multiply(stat_ext, coeff)\n",
        "\treturn(torch.sum(lamda, axis = -1))\n",
        "\n",
        "### ASK modulation\n",
        "def ASK(lmbd, r):\n",
        "\treturn(-np.sqrt(P)+lmbd*2*np.sqrt(P)/(r-1))\n",
        "\n",
        "### Minimum-Distance decoding\n",
        "def MD(y_recvd, delt, r):\n",
        "\treturn(torch.round((y_recvd/delt+K*np.sqrt(P)/delt-1/2)))\n",
        "\n",
        "### Lattice decoding (Successive-Cancelllation)\n",
        "def LatD(y_hat, b, w, d_):\n",
        "  if torch.sum(y_hat>= w) == 0 and torch.numel(b) == d_:\n",
        "    return(b)\n",
        "  else:\n",
        "    b = torch.concatenate((b, (y_hat%w).reshape(1,len(y_hat))))\n",
        "    return(LatD((y_hat-y_hat%w)/w, b, w, d_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68trxEFPat5v"
      },
      "source": [
        "**Main** **code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYaAEJlLa8nX"
      },
      "outputs": [],
      "source": [
        "d = 64\t\t                                                                              #### dimension\n",
        "cnt = 0\n",
        "B_range = [2,4,8,16,32,64,128,256,512,1024,2048,4096]\n",
        "MSE1_B = [0]*len(B_range)\n",
        "MSE2_B = [0]*len(B_range)\n",
        "\n",
        "for b in B_range:\n",
        "  Clients = [1000]\n",
        "  SMSE1_K = [0]*len(Clients)                                                            #### S indicates 'for side info'\n",
        "  SMSE2_K = [0]*len(Clients)\n",
        "\n",
        "  MSE1_K = [0]*len(Clients)\n",
        "  MSE2_K = [0]*len(Clients)\n",
        "  I = 20\t\t                                                                            #### monte-carlo iterations\n",
        "  for i in range(len(Clients)):\n",
        "    K = Clients[i]\n",
        "    print('Clients: {}, dimension: {}, MC_iter: {}'.format(K, d, I))\n",
        "    sigma_range =[0.01732]                                                              #### sig^prime in paper = 3 x sig\n",
        "\n",
        "    SMSE1_K_sig = [0.0]\n",
        "    SMSE2_K_sig = [0.0]\n",
        "\n",
        "    MSE1_K_sig = [0.0]\n",
        "    MSE2_K_sig = [0.0]\n",
        "\n",
        "    sig = sigma_range[0]\n",
        "\n",
        "    SMSE1_K_sig_I = [0.0]*I\n",
        "    SMSE2_K_sig_I = [0.0]*I\n",
        "\n",
        "    MSE1_K_sig_I = [0.0]*I\n",
        "    MSE2_K_sig_I = [0.0]*I\n",
        "\n",
        "    mean = 2*(torch.rand(d).to(device)-0.5)                                             #### True gradients in [-1,1]\n",
        "    for k in range(I):\n",
        "      snr_range = [180]\n",
        "      SMSE1_K_sig_I_snr = [0.0]*len(snr_range)\n",
        "      SMSE2_K_sig_I_snr = [0.0]*len(snr_range)\n",
        "\n",
        "      MSE1_K_sig_I_snr = [0.0]*len(snr_range)\n",
        "      MSE2_K_sig_I_snr = [0.0]*len(snr_range)\n",
        "\n",
        "\n",
        "      for l in range(len(snr_range)):\n",
        "        print('\\n Experiment for Iteration = {}, B = {}, SNR = {}dB'.format(k, b, snr_range[l]))\n",
        "        input_avg = torch.zeros(d).to(device)\n",
        "        q_input_avg = torch.zeros(d).to(device)\n",
        "        output_avg = torch.zeros(d).to(device)\n",
        "        psi_1 = []\n",
        "        psi_2 = []\n",
        "        x_e_1 = []\n",
        "        x_e_2 = []\n",
        "        dbSNR = snr_range[l]                                                            #### SNR in dB\n",
        "        SNR = 10**(dbSNR/10.0)                                                          #### SNR in units/units\n",
        "        npr = 1.0                                                                       #### Noise power\n",
        "        P = SNR*npr/K                                                                   #### Signal power allowed per client\n",
        "\n",
        "        v_1 = int(d)+1                                                                  #### No. of quantization levels\n",
        "        w_1 = v_1*K + 1\n",
        "        v_2 = int(np.ceil(np.sqrt(np.log(K**1.5)*np.sqrt(96)))*400)                     #### Boosting parameter for DAQ\n",
        "        w_2 = K*v_2+1\n",
        "\n",
        "        p_1 = min(d, max(1, int(np.log(np.sqrt(2*K*SNR/np.log(K))+1)/np.log(w_1))))     #### Block size\n",
        "        p_2 = min(d, max(1, int(np.log(np.sqrt(2*K*SNR/np.log(K))+1)/np.log(w_2))))\n",
        "\n",
        "        num_blocks_1 = int(np.ceil(d/p_1))\n",
        "        num_blocks_2 = int(np.ceil(d/p_2))\n",
        "\n",
        "        d_ext_1 = num_blocks_1*p_1\n",
        "        d_ext_2 = num_blocks_2*p_2\n",
        "        M = b/K*int(np.ceil(np.sqrt(np.log(K**1.5))))                \t\t\t\t\t\t        #### The high probability region [-M, M] used for correlated sampling in DAQ\n",
        "\n",
        "\n",
        "        print('\\nFor side info: v_1= {}, w_1= {}, num_Blocks_1 = {}, blocksize_1 = {}'.format(v_1, w_1, num_blocks_1, p_1))\n",
        "        print('For DAQ: v_2= {}, w_2= {}, num_Blocks_2 = {}, blocksize_2 = {}'.format(v_2, w_2, num_blocks_2, p_2))\n",
        "\n",
        "        r_1 = (w_1**p_1-1)/K + 1                                                        #### Number of ASK codewords in first transmission\n",
        "        del_1 = 2*np.sqrt(P)/(r_1-1)\n",
        "\n",
        "        r_2 = (w_2**p_2-1)/K + 1                                                        #### Number of ASK codewords in second transmission\n",
        "        del_2 = 2*np.sqrt(P)/(r_2-1)\n",
        "\n",
        "        U_shared = 2*M*(torch.rand(K, v_2, d).to(device)-0.5)                           #### clients in C_2 x Boosting x dimensions. U~[-M,M] iid I times\n",
        "        diagonal = 2*torch.randint(0,2,(d,)).to(device)-torch.ones(d).to(device)        #### Random signs. Same for each client\n",
        "        for client in range(2*K):\n",
        "          t = 6*sig*(torch.rand(d).to(device)-0.5)                                      #### Noise in [-3\\sigma, +3\\sigma].\n",
        "          x = mean + t                                                                  #### Noisy gradient in [-1-3sigma, 1+3sigma]\n",
        "          B = b*np.sqrt(d)                                                              #### Maximum norm of noisy grad                                                                     #### E[x] = mean; var(x) = var(t) = 3sig^2 = sig_paper^2/d; norm(x) <= B^2 = B_paper^2 = d(1+3sig)^2\n",
        "\n",
        "          if (client<K):\n",
        "            ''' PERFORM UNIFORM QUANTIZATION '''\n",
        "\n",
        "            Q_space = -B/K + torch.arange(v_1).to(device)*2*B/K/(v_1-1)                 #### Quantization points in [-B/K,B/K]\n",
        "            x_uq = UQ(x, B, v_1, Q_space)\n",
        "            q_input_avg = q_input_avg - B/K + 2*B*x_uq/K/(v_1-1)\n",
        "\n",
        "            ''' LATTICE ENCODING '''\n",
        "            x_uq_lenc = LatE(x_uq, p_1, num_blocks_1, w_1, d_ext_1)\n",
        "\n",
        "            ''' ASK MODULATION '''\n",
        "            x_uq_lenc_ask  = ASK(x_uq_lenc, r_1)\n",
        "            psi_1.append(x_uq_lenc_ask)\n",
        "            x_e_1.append(x_uq)\n",
        "\n",
        "          else:\n",
        "            input_avg = x + input_avg\n",
        "\n",
        "            ''' PERFORM DAQ '''\n",
        "            sgn_x = torch.multiply(x/K, diagonal)\n",
        "            rot_x = fwht(sgn_x, False)/(d**0.5)\n",
        "            x_rdaq = sum(torch.where((U_shared[client-K]<= rot_x), 1, 0))               #### Sum after different boosting iterations.\n",
        "            x_rdaq_lenc = LatE(x_rdaq, p_2, num_blocks_2, w_2, d_ext_2)\n",
        "            x_rdaq_lenc_ask = ASK(x_rdaq_lenc, r_2)\n",
        "            psi_2.append(x_rdaq_lenc_ask)\n",
        "            x_e_2.append(x_rdaq)\n",
        "\n",
        "        ''' First MAC transmission '''\n",
        "        y_1 = sum(psi_1)+ np.sqrt(npr)*torch.randn(num_blocks_1).to(device)             #### Adding awgn noise\n",
        "        x_1_hat = MD(y_1, del_1, r_1)                                                   #### Min-distance Decoding\n",
        "        x_1_hat_ldec = LatD(x_1_hat, torch.Tensor([]).to(device), w_1, d_ext_1)         #### Lattice Decoding\n",
        "        x_1_hat_ldec = x_1_hat_ldec.transpose(0, 1).flatten()\n",
        "        x_1_hat_ldec_uq = -B + x_1_hat_ldec[:d]*2*B/K/(v_1-1)                           #### Mean estimate of gradients in C_1 group\n",
        "\n",
        "\n",
        "        ''' Preparing the side information: rotation and 1-bit quantization '''\n",
        "        norm_side_info = x_1_hat_ldec_uq/K\n",
        "        sgn_norm_side_info = torch.multiply(norm_side_info, diagonal)\n",
        "        rot_sgn_norm_side_info = fwht(norm_side_info, False)/(d**0.5)\n",
        "        ss = (torch.abs(rot_sgn_norm_side_info)<=M)*rot_sgn_norm_side_info\n",
        "        q_rot_sgn_norm_side_info = torch.where(U_shared<=ss, 1, 0)\n",
        "        ind_1 = sum(torch.sum(q_rot_sgn_norm_side_info, axis = 1))\n",
        "        print('\\nSide information constructed!')\n",
        "\n",
        "        ''' Second MAC transmission '''\n",
        "        y_2 = sum(psi_2) + np.sqrt(npr)*torch.randn(num_blocks_2).to(device)\n",
        "        x_2_hat = MD(y_2, del_2, r_2)                                                   #### Decoded sum of ASK codeword\n",
        "        x_2_hat_ldec = LatD(x_2_hat, torch.Tensor([]).to(device), w_2, d_ext_2)         #### Decoded sum of lattice coefficients\n",
        "        x_2_hat_ldec = x_2_hat_ldec.transpose(0, 1).flatten()\n",
        "        ind_2 = x_2_hat_ldec\n",
        "        output = 2*M/v_2*torch.multiply(diagonal, fwht((d**0.5)*(ind_2[:d] - ind_1[:d]),True)) + x_1_hat_ldec_uq\n",
        "\n",
        "        total_num_blocks = num_blocks_1 + num_blocks_2\n",
        "        print('WZ estimation done! Total channel uses = ', total_num_blocks)\n",
        "        print()\n",
        "        MSE_1 = output - mean                                                           #### MSE w.r.t true grad (over MAC)\n",
        "        MSE_2 = q_input_avg - mean                                                      #### MSE w.r.t avg. of quant. noisy grad (noiseless channel)\n",
        "\n",
        "        SMSE_1 = x_1_hat_ldec_uq - mean                                                 #### MSE w.r.t true grad (over MAC)\n",
        "        SMSE_2 = q_input_avg - mean                                                     #### MSE w.r.t avg. of quant. noisy grad (noiseless channel)\n",
        "\n",
        "        print('TM:', mean.norm(), 'QEM:', q_input_avg.norm(), 'WZ:', output.norm(), 'UQ:', x_1_hat_ldec_uq.norm())\n",
        "        print('WZ Error:', MSE_1.norm()*np.sqrt(total_num_blocks), 'UQ Error', SMSE_1.norm()*np.sqrt(total_num_blocks))\n",
        "\n",
        "        MSE1_K_sig_I_snr[l] = MSE_1.norm()*np.sqrt(total_num_blocks)\n",
        "        MSE2_K_sig_I_snr[l] = MSE_2.norm()*np.sqrt(total_num_blocks)\n",
        "\n",
        "        SMSE1_K_sig_I_snr[l] = SMSE_1.norm()*np.sqrt(num_blocks_1)\n",
        "        SMSE2_K_sig_I_snr[l] = SMSE_2.norm()*np.sqrt(num_blocks_1)\n",
        "\n",
        "      MSE1_K_sig_I[k] = MSE1_K_sig_I_snr\n",
        "      MSE2_K_sig_I[k] = MSE2_K_sig_I_snr\n",
        "\n",
        "      SMSE1_K_sig_I[k] = SMSE1_K_sig_I_snr\n",
        "      SMSE2_K_sig_I[k] = SMSE2_K_sig_I_snr\n",
        "\n",
        "\n",
        "    MSE1_K_sig = np.array(sum(torch.Tensor(MSE1_K_sig_I)).to('cpu')/I)\n",
        "    MSE2_K_sig = np.array(sum(torch.Tensor(MSE2_K_sig_I)).to('cpu')/I)\n",
        "\n",
        "    print('Average WZ Error after {} iterations: {}'.format(I, MSE1_K_sig))\n",
        "\n",
        "    SMSE1_K_sig = np.array(sum(torch.Tensor(SMSE1_K_sig_I)).to('cpu')/I)\n",
        "    SMSE2_K_sig = np.array(sum(torch.Tensor(SMSE2_K_sig_I)).to('cpu')/I)\n",
        "\n",
        "    MSE1_K[i] = MSE1_K_sig\n",
        "    MSE2_K[i] = MSE2_K_sig\n",
        "\n",
        "    SMSE1_K[i] = SMSE1_K_sig\n",
        "    SMSE2_K[i] = SMSE2_K_sig\n",
        "\n",
        "  MSE1_B[cnt] = MSE1_K\n",
        "  MSE2_B[cnt] = MSE2_K\n",
        "  cnt+=1\n",
        "\n",
        "#np.savetxt(\"RMSE_CUQ_v_\"+str(v)+\"_\"+str(d)+\".dat\", MSE_CUQ, delimiter =\", \", fmt ='% s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsQz-Et_ingZ"
      },
      "source": [
        "**Plotting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSQ0hw-virFR"
      },
      "outputs": [],
      "source": [
        "pts = 14 ## Number of points for plotting. Maximum = len(sigma_range)\n",
        "font = {'weight': 'normal', 'size': 14}\n",
        "matplotlib.rc('font', **font)\n",
        "\n",
        "Tot_clnts = [i*2 for i in Clients]\n",
        "for b in range(len(B_range)):\n",
        "  B1 = B_range[b]\n",
        "  plt.plot(Tot_clnts[:pts], MSE1_B[b][:pts], label='MSE_TM_WZ_OTA')\n",
        "  plt.plot(Tot_clnts[:pts], MSE2_B[b][:pts], label='MSE_TM_WZ_OTA (noiseless)')\n",
        "  plt.legend()\n",
        "  plt.xlabel('K')\n",
        "  plt.ylabel('RMSE x l')\n",
        "  plt.xscale('log')\n",
        "  plt.yscale('log')\n",
        "  plt.xticks(ticks= Tot_clnts[:pts], labels = Tot_clnts[:pts])\n",
        "  plt.title('d='+str(d)+', iters='+str(I)+', B/sigma='+str(B1/sig)+'SNR='+str(SNR))\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "for b in range(len(B_range)):\n",
        "  B1 = B_range[b]\n",
        "  for i in range(len(Clients)):\n",
        "    K = Clients[i]\n",
        "    plt.plot(snr_range[:pts], MSE1_B[b][i][:pts], label='MSE_TM_WZ_OTA_K='+str(2*K))\n",
        "    plt.plot(snr_range[:pts], MSE2_B[b][i][:pts], label='MSE_TM_WZ_OTA_K='+str(2*K)+' (noiseless)')\n",
        "    plt.legend()\n",
        "    plt.xlabel('SNR')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.xticks(ticks= snr_range[:pts], labels=snr_range[:pts])\n",
        "    plt.title('d='+str(d)+', iters='+str(I)+', B/sigma='+str(B1/sig))\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "b_by_sig = [B_range[b]/np.sqrt(3)/sig for b in range(len(B_range))]\n",
        "\n",
        "MSE1_modified = np.array(MSE1_B).transpose()\n",
        "MSE2_modified = np.array(MSE2_B).transpose()\n",
        "\n",
        "for i in range(len(Clients)):\n",
        "  K = Clients[i]\n",
        "\n",
        "  for k in range(len(snr_range)):\n",
        "    plt.plot(b_by_sig[:pts], MSE1_modified[k][i][:pts], label='MSE_TM_WZ_OTA')\n",
        "    plt.plot(b_by_sig[:pts], MSE4_modified[k][i][:pts], label='MSE_TM_WZ_OTA'+' (noiseless)')\n",
        "    plt.legend()\n",
        "    plt.xlabel('b_by_sig')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.xscale('log')\n",
        "    plt.xticks(ticks= b_by_sig[:pts], labels=b_by_sig[:pts])\n",
        "    plt.title('d='+str(d)+', iter='+str(I)+', K='+str(2*K)+', SNR = '+str(snr_range[k])+'dB')\n",
        "    plt.grid()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}